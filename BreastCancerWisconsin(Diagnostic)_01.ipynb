{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0B1Diibty9a7",
        "tHJuFsVC2EQi",
        "Se4c3qSX0b0Y",
        "XgoS0NMk1yia",
        "qAH7qDMrz7Fi",
        "ENecHtNR2B1N",
        "DTkEUP2j-SnU"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Brustkrebs Wisconsin (Diagnostik) "
      ],
      "metadata": {
        "id": "3JXjY-Abp96g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Installieren der Bibliotheken"
      ],
      "metadata": {
        "id": "SFG5h36BqkyF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ich habe für mein KI-Projekt den Datensatz \"Breast Cancer Wisconsin (Diagnostic)\" aus dem UCI Maschine Learning Repository gewählt, welcher medizinische Daten zur Diagnose von Brustkrebs enthält.\n",
        "\n",
        "Zunächst müssen wir sicherstellen, dass wir die benötigten Bibliotheken installiert haben. In diesem Fall benötigen wir Pandas, Scikit-Learn und Seaborn.\n"
      ],
      "metadata": {
        "id": "UwX1E0YzzIXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install scikit-learn\n",
        "!pip install seaborn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWyBUcOJPt6X",
        "outputId": "424bb208-d899-4fc7-edc3-1abe9bd7568c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.9/dist-packages (0.12.2)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.9/dist-packages (from seaborn) (1.5.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.9/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.9/dist-packages (from seaborn) (1.22.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (8.4.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (5.12.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.25->seaborn) (2022.7.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.1->seaborn) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Datensatz einbinden"
      ],
      "metadata": {
        "id": "eU4KZdjMrWK_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dann können wir den Datensatz aus dem UCI-Repository laden und in ein Pandas DataFrame umwandeln."
      ],
      "metadata": {
        "id": "KVVaiLSNPxQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data'\n",
        "breast_cancer_data = pd.read_csv(url, header=None)\n"
      ],
      "metadata": {
        "id": "WsB4LXeuP04v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dies lädt den Brustkrebs-Datensatz und speichert ihn in der Variable \"breast_cancer_data\". Die Spaltennamen des DataFrame werden in der ursprünglichen Datenbeschreibung angegeben und müssen daher manuell hinzugefügt werden."
      ],
      "metadata": {
        "id": "dWktbBxGP2sQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave_points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave_points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave_points_worst', 'symmetry_worst', 'fractal_dimension_worst']\n",
        "breast_cancer_data.columns = columns"
      ],
      "metadata": {
        "id": "wOU1dwXtP5br"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jetzt können wir uns einen Überblick über die Daten verschaffen, indem wir die ersten fünf Zeilen des DataFrame ausgeben."
      ],
      "metadata": {
        "id": "naW85xCyP7du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(breast_cancer_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXN1UEeAP9h3",
        "outputId": "8025b211-ae9d-4c26-8fe0-da40064683bd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
            "0    842302         M        17.99         10.38          122.80     1001.0   \n",
            "1    842517         M        20.57         17.77          132.90     1326.0   \n",
            "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
            "3  84348301         M        11.42         20.38           77.58      386.1   \n",
            "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
            "\n",
            "   smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  \\\n",
            "0          0.11840           0.27760          0.3001              0.14710   \n",
            "1          0.08474           0.07864          0.0869              0.07017   \n",
            "2          0.10960           0.15990          0.1974              0.12790   \n",
            "3          0.14250           0.28390          0.2414              0.10520   \n",
            "4          0.10030           0.13280          0.1980              0.10430   \n",
            "\n",
            "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
            "0  ...         25.38          17.33           184.60      2019.0   \n",
            "1  ...         24.99          23.41           158.80      1956.0   \n",
            "2  ...         23.57          25.53           152.50      1709.0   \n",
            "3  ...         14.91          26.50            98.87       567.7   \n",
            "4  ...         22.54          16.67           152.20      1575.0   \n",
            "\n",
            "   smoothness_worst  compactness_worst  concavity_worst  concave_points_worst  \\\n",
            "0            0.1622             0.6656           0.7119                0.2654   \n",
            "1            0.1238             0.1866           0.2416                0.1860   \n",
            "2            0.1444             0.4245           0.4504                0.2430   \n",
            "3            0.2098             0.8663           0.6869                0.2575   \n",
            "4            0.1374             0.2050           0.4000                0.1625   \n",
            "\n",
            "   symmetry_worst  fractal_dimension_worst  \n",
            "0          0.4601                  0.11890  \n",
            "1          0.2750                  0.08902  \n",
            "2          0.3613                  0.08758  \n",
            "3          0.6638                  0.17300  \n",
            "4          0.2364                  0.07678  \n",
            "\n",
            "[5 rows x 32 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Datenanalyse"
      ],
      "metadata": {
        "id": "0pbYLlkuroQf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Als nächstes können wir die Daten analysieren, um herauszufinden, wie die verschiedenen Merkmale miteinander korrelieren und wie die Diagnose von Brustkrebs bestimmt werden kann."
      ],
      "metadata": {
        "id": "4oIbF7WHP_lI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.pairplot(breast_cancer_data, hue='diagnosis')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zgYyS-uCQBD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dies erstellt eine Paarplot-Matrix mit den verschiedenen Merkmalen als Achsen und Farbkodierung nach der Diagnose von Brustkrebs. Dies hilft uns, Muster in den Daten zu erkennen und zu verstehen, wie die verschiedenen Merkmale miteinander korrelieren."
      ],
      "metadata": {
        "id": "5neqorD_QFnA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dokumentation zu Abschnitt 3:"
      ],
      "metadata": {
        "id": "E1O0a4Svx7va"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeile 1:** Am Anfang wird die Bibliothek `matplotlib` importiert und der Namespace mit dem Alias `plt` versehen, um darauf zugreifen zu können. Dies ermöglicht die Verwendung von Funktionen und Klassen aus dieser Bibliothek in dem Programm, in dem diese Zeile aufgerufen wird."
      ],
      "metadata": {
        "id": "SvN4c3GTys5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeile 2:** Es wird die Bibliothek \"seaborn\" importiert. Seaborn ist eine Python-Datenvisualisierungsbibliothek, die auf der Bibliothek \"matplotlib\" basiert. Sie bietet eine einfache Möglichkeit, ansprechende Grafiken zu erstellen und ist besonders nützlich für die Darstellung statistischer Daten."
      ],
      "metadata": {
        "id": "IPWu0A_WzP7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeile 4:** Die Funktion `sns.pairplot()` aus dem Python-Modul Seaborn erstellt ein Raster von Scatterplots für alle möglichen Kombinationen von Merkmalen in einem gegebenen Datensatz. Jeder Scatterplot zeigt die Beziehung zwischen zwei Merkmalen als Punktwolke an. Der Parameter hue definiert eine Kategorievariable, die zur Färbung der Punktwolken verwendet wird.\n",
        "\n",
        "In diesem Fall wird die Funktion `sns.pairplot()` auf den Datensatz `breast_cancer_data` angewendet und die Punktwolken werden nach der Diagnose der Brustkrebs-Patienten (M für maligne und B für benign) eingefärbt. Das resultierende Raster von Scatterplots kann helfen, Zusammenhänge zwischen verschiedenen Merkmalen und der Diagnose von Brustkrebs zu visualisieren."
      ],
      "metadata": {
        "id": "4PfUpJ1QyGov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeile 5:** Die Funktion `plt.show()` zeigt das aktuelle Diagramm an."
      ],
      "metadata": {
        "id": "GpJGEELHz92q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. KI-Modell trainieren"
      ],
      "metadata": {
        "id": "RH5kyJSQyaQU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Schließlich können wir ein KI-Modell trainieren, um die Diagnose von Brustkrebs zu bestimmen. In diesem Fall verwenden wir eine logistische Regression mit Scikit-Learn."
      ],
      "metadata": {
        "id": "XkT0bQBLyaIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split  # Importieren der fehlenden Bibliothek\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "# Laden der Daten\n",
        "breast_cancer_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data', header=None)\n",
        "\n",
        "# Setzen der Spaltennamen\n",
        "breast_cancer_data.columns = ['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave_points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave_points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave_points_worst', 'symmetry_worst', 'fractal_dimension_worst']\n",
        "\n",
        "# Auswahl der Merkmale, die als Eingabe in das Modell verwendet werden sollen\n",
        "features = ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave_points_mean', 'symmetry_mean', 'fractal_dimension_mean']\n",
        "\n",
        "# Aufteilen der Daten in Trainings- und Testdatensätze\n",
        "X = breast_cancer_data[features]\n",
        "y = breast_cancer_data['diagnosis']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Training des KI-Modells\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Vorhersage auf Testdaten und Bewertung des Modells\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "print('Accuracy:', accuracy)\n",
        "print('Confusion Matrix:\\n', confusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb44Rhv1QIB1",
        "outputId": "c0160522-5f1d-49b2-b858-a3e9786ecb5e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9298245614035088\n",
            "Confusion Matrix:\n",
            " [[66  5]\n",
            " [ 3 40]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zunächst wählen wir die Merkmale aus, die als Eingabe in das Modell verwendet werden sollen. Dann teilen wir die Daten in Trainings- und Testdatensätze auf.\n",
        "\n",
        "Wir erstellen ein Objekt der Klasse LogisticRegression und trainieren das Modell mit den Trainingsdaten.\n",
        "\n",
        "Dann führen wir Vorhersagen auf den Testdaten durch und berechnen die Genauigkeit des Modells sowie die Confusion Matrix, um zu sehen, wie gut das Modell bei der Vorhersage von positiven und negativen Diagnosen abschneidet."
      ],
      "metadata": {
        "id": "3AWxt_rtSNXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dokumentation zu Abschnitt 4:"
      ],
      "metadata": {
        "id": "XiAmH3n33igL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeile 1-4:** Zu Beginn werden die benötigten Bibliotheken für die logistische Regression geladen. `train_test_split` wird verwendet, um die Daten in Trainings- und Testdatensätze aufzuteilen. `LogisticRegression` ist der Klassifikationsalgorithmus, der für das Training des Modells verwendet wird. `accuracy_score` und `confusion_matrix` werden verwendet, um die Leistung des Modells zu bewerten. pandas wird verwendet, um die Daten als DataFrame zu laden und zu manipulieren."
      ],
      "metadata": {
        "id": "eSpStnJe6CQY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeile 7:** Anschließend wird der Datensatz \"Breast Cancer Wisconsin (Diagnostic)\" von der UCI Machine Learning Repository über die URL https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data heruntergeladen und in ein Pandas DataFrame-Objekt namens `breast_cancer_data` eingelesen. Der Parameter `header=None` gibt an, dass der Datensatz keine Spaltenüberschriften enthält."
      ],
      "metadata": {
        "id": "mAjRAsYB7CYf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeile 10:** Zunächst werden die Spaltennamen des Dataframes `breast_cancer_data` neu definiert. Es wird eine Liste mit den Namen der Spalten erstellt und diese dann dem Dataframe als neue Spaltennamen zugewiesen."
      ],
      "metadata": {
        "id": "tKRpWCZZ7Lem"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeile 13:** Als Nächstes wird eine Liste mit den Namen der ausgewählten Features erstellt. Es handelt sich um 10 Merkmale der Brustkrebs-Diagnose, die aufgrund ihrer medizinischen Relevanz ausgewählt wurden. Diese Merkmale werden später für das Training des Modells verwendet."
      ],
      "metadata": {
        "id": "E358Swwf7WUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeile 16-18:** Im Folgenden wird der Datensatz in Trainings- und Testdaten aufgeteilt, um das Modell zu trainieren und zu testen.\n",
        "\n",
        "Zunächst werden die Features, also die unabhängigen Variablen, aus dem Datensatz extrahiert und in die Variable X gespeichert. Die abhängige Variable, also die zu prognostizierende Variable, wird in der Variable y gespeichert.\n",
        "\n",
        "Dann werden die Trainings- und Testdaten mit Hilfe der Funktion `train_test_split` aus dem `sklearn.model_selection`-Modul erstellt. Dabei werden X und y übergeben, sowie der Testdatenanteil `test_size=0.2` (also 20% des Datensatzes), und der Zufallszahlengenerator `random_state=42`, um die Ergebnisse reproduzierbar zu machen. Die Funktion teilt die Daten zufällig in Trainings- und Testdaten auf und gibt vier Variablen zurück, nämlich `X_train` (die Trainingsdaten für X), `X_test` (die Testdaten für X), `y_train` (die Trainingsdaten für y) und `y_test` (die Testdaten für y)."
      ],
      "metadata": {
        "id": "ke3SS9UM72cA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeile 21f.:** Zeile 21 erstellt eine Instanz des LogisticRegression-Klassifikators aus Scikit-Learn. Danach wird das Modell mit den Trainingsdaten `X_train` und den zugehörigen Zielwerten `y_train` trainiert. Das Modell versucht dabei, eine Entscheidungsgrenze zu finden, die die Trainingsdaten möglichst gut voneinander trennt."
      ],
      "metadata": {
        "id": "MmbfHN4O8IIH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeile 25:** Es wird die Vorhersage des Modells für die Testdaten `X_test` durchgeführt und das Ergebnis in `y_pred` gespeichert. Die predict-Methode des Modells verwendet die trainierten Gewichte, um eine Vorhersage für jede Instanz in `X_test` zu treffen."
      ],
      "metadata": {
        "id": "JBcwAO6R8vxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeile 26:** Die `accuracy_score` Funktion berechnet die Genauigkeit des Modells, indem sie die Vorhersagen des Modells (y_pred) mit den tatsächlichen Labels (y_test) vergleicht und die Anzahl der korrekten Vorhersagen durch die Gesamtzahl der Vorhersagen teilt. Die Genauigkeit ist ein gängiges Maß für die Leistung von Klassifikatoren und gibt an, wie gut das Modell in der Lage ist, korrekte Vorhersagen zu treffen. Eine Genauigkeit von 1,0 bedeutet, dass alle Vorhersagen des Modells korrekt sind, während eine Genauigkeit von 0,5 bedeutet, dass das Modell zufällig vorhersagt."
      ],
      "metadata": {
        "id": "j6noCiUo9Cxx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeile 27:** `confusion_matrix` ist eine Funktion aus dem `sklearn.metrics `Modul und wird verwendet, um eine Konfusionsmatrix für die Vorhersagen eines Klassifikators zu berechnen. Eine Konfusionsmatrix ist eine Tabelle, die den Vergleich zwischen den tatsächlichen und den vorhergesagten Werten darstellt. In der Regel wird eine Konfusionsmatrix für eine binäre Klassifikation verwendet und zeigt die Anzahl der Vorhersagen, die korrekt und inkorrekt waren."
      ],
      "metadata": {
        "id": "zqT7S7_B9faC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeile 28:** Die Zeile gibt die Genauigkeit (Accuracy) des trainierten Modells aus. Die Genauigkeit gibt an, wie viele der Vorhersagen des Modells tatsächlich korrekt waren, d.h. wie gut das Modell in der Lage ist, zwischen den beiden Klassen (Maligne und Benigne) zu unterscheiden. Die Accuracy ist definiert als die Anzahl der korrekten Vorhersagen geteilt durch die Gesamtanzahl der Vorhersagen."
      ],
      "metadata": {
        "id": "cbGkPVrf9zzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeile 29:** Die Konfusionsmatrix ist in der Regel in der Form [ [TN FP] [FN TP] ] dargestellt, wobei TN, FP, FN und TP die Abkürzungen für die vier möglichen Ergebnisse *True Negative*, *False Positive*, *False Negative* und *True Positive* sind.\n",
        "\n",
        "In dieser spezifischen Confusion Matrix bedeutet das:\n",
        "\n",
        "*    Die obere linke Zelle (66) zeigt, wie viele Datenpunkte vom Modell korrekt als Negative (TN) klassifiziert wurden.\n",
        "*   Die obere rechte Zelle (5) zeigt, wie viele Datenpunkte vom Modell fälschlicherweise als Positive (FP) klassifiziert wurden.\n",
        "*   Die untere linke Zelle (3) zeigt, wie viele Datenpunkte vom Modell fälschlicherweise als Negative (FN) klassifiziert wurden.\n",
        "*   Die untere rechte Zelle (40) zeigt, wie viele Datenpunkte vom Modell korrekt als Positive (TP) klassifiziert wurden.\n",
        "\n",
        "Zusammenfassend bedeutet dies, dass das Modell 66 von 71 negativen Fällen korrekt klassifiziert hat und 40 von 43 positiven Fällen korrekt klassifiziert hat. Das Modell hat 5 Fälle fälschlicherweise als positiv eingestuft und 3 Fälle fälschlicherweise als negativ eingestuft."
      ],
      "metadata": {
        "id": "WslMLkD73iXi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Testen des KI-Models anhand eines Patienten"
      ],
      "metadata": {
        "id": "gGtI9xl9ZChZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_features = [13.25, 20.38, 88.44, 538.0, 0.1045, 0.1552, 0.253, 0.086, 0.1928, 0.0654]\n",
        "test_features = pd.DataFrame([test_features], columns=features)\n",
        "prediction = model.predict(test_features)\n",
        "print('Prediction:', prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR00vBgTZCLA",
        "outputId": "b149065f-b5ec-4ae1-c6cb-7c114e2ef24c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: ['M']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dokumentation zu Abschnitt 5:"
      ],
      "metadata": {
        "id": "eU3IB0inon2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeile 1:** Es wird eine Liste test_features erstellt, die die Werte der 10 ausgewählten Merkmale für ein Beispiel von Brustkrebsdaten enthält. Diese Werte wurden manuell eingegeben und repräsentieren ein hypothetisches Beispiel für einen Patienten."
      ],
      "metadata": {
        "id": "TVJiHAZDl23i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeile 2:** Es wird die Liste der Testmerkmale in ein Pandas DataFrame umgewandelt. Dabei wird die Liste in einer Zeile mit den Spaltennamen aus der Variable features angeordnet. So wird sichergestellt, dass die Daten im richtigen Format vorliegen, um vom trainierten KI-Modell verarbeitet werden zu können."
      ],
      "metadata": {
        "id": "UVZpzC7Gob2x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeile 3:** Jetzt wird das trainierte Modell `model` verwendet, um Vorhersagen für die übergebenen Testdaten `test_features` zu machen. `model.predic(test_features)`wendet das Modell auf die Testdaten an und gibt die Vorhersage für jede Zeile zurück. In diesem Fall wird nur eine Zeile von Testdaten verwendet, so dass die Vorhersage für diese eine Zeile zurückgegeben wird."
      ],
      "metadata": {
        "id": "3K7d83TtoVxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zeile 4:** Die Ausgabe der Vorhersage wird mit dieser Zeile ausgegeben. `prediction` enthält das Ergebnis des Modells auf den Testdaten, die durch `test_features` repräsentiert werden. In diesem Fall ist die Vorhersage 'M', was bedeutet, dass das Modell vorhersagt, dass der Tumor bösartig ist."
      ],
      "metadata": {
        "id": "BvL0MaippRLN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hintergrundwissen:"
      ],
      "metadata": {
        "id": "mgkc0op61oeG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pandas"
      ],
      "metadata": {
        "id": "0B1Diibty9a7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas ist eine Python-Bibliothek, die speziell für die Datenanalyse und -manipulation entwickelt wurde. Pandas bietet leistungsstarke und flexible Funktionen, mit denen Daten in verschiedenen Formaten wie CSV, Excel, SQL-Datenbanken und mehr eingelesen, verarbeitet, transformiert und ausgegeben werden können. Die Bibliothek ist in der Lage, große Datensätze zu handhaben und bietet eine Vielzahl von Funktionen, einschließlich:\n",
        "\n",
        "1.   Datenfilterung und -abfrage\n",
        "2.   Datenmanipulation und -transformation\n",
        "3.   Zusammenfassung und statistische Analyse von Daten\n",
        "4.   Zeitreihenanalyse\n",
        "5.   Visualisierung von Daten\n",
        "6.   Datensatz-Zusammenführung und -Verknüpfung\n",
        "\n",
        "Pandas ist eine der beliebtesten Bibliotheken für Datenanalyse in Python und wird häufig in der Wissenschaft, Finanzen, Statistik, Ökonomie und anderen Bereichen eingesetzt, in denen Datenanalysen durchgeführt werden."
      ],
      "metadata": {
        "id": "4E_Omr9QzAUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scikit-Learn"
      ],
      "metadata": {
        "id": "tHJuFsVC2EQi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scikit-Learn ist eine in Python geschriebene Open-Source-Bibliothek, die eine Vielzahl von Machine-Learning-Algorithmen und -Tools für Datenanalyse und -verarbeitung bereitstellt. Sie bietet eine konsistente API und ermöglicht es Entwicklern und Data Scientists, Machine-Learning-Modelle schnell zu erstellen, zu trainieren und zu evaluieren. Die Bibliothek bietet auch Funktionen für Daten-Vorverarbeitung, Dimensionsreduktion, Feature-Extraktion, Clustering, Regression und Klassifikation sowie Modellvalidierung und -auswahl. Scikit-Learn ist eine der am häufigsten verwendeten Bibliotheken für Machine-Learning in Python."
      ],
      "metadata": {
        "id": "_aYJkCpi2B9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seaborn"
      ],
      "metadata": {
        "id": "Se4c3qSX0b0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seaborn ist eine Python-Bibliothek zur Erstellung von Datenvisualisierungen. Die Bibliothek basiert auf der beliebten Matplotlib-Bibliothek und bietet eine höhere Abstraktionsebene sowie attraktivere Standarddesigns für Diagramme und Plots. Mit Seaborn können Benutzer leicht verschiedene Arten von Diagrammen wie Streudiagramme, Balkendiagramme, Boxplots und Heatmaps erstellen.\n",
        "\n",
        "Einige der wichtigsten Funktionen von Seaborn sind:\n",
        "\n",
        "1.   Einfache Erstellung von Standardplots und komplexeren statistischen Plots.\n",
        "2.   Möglichkeit zur Anpassung von Farbpaletten und Stilen für die Darstellung von Daten.\n",
        "3.   Verwendung von Datenframes von Pandas, um Diagramme zu erstellen, wodurch es einfacher wird, Daten zu manipulieren und zu visualisieren.\n",
        "4.   Unterstützung für mehrere Diagramme in einer Figur sowie Erstellung von Subplots.\n",
        "\n",
        "Seaborn wird häufig von Datenwissenschaftlern und Analysten verwendet, um komplexe Datenmuster zu visualisieren und Erkenntnisse aus Daten zu gewinnen."
      ],
      "metadata": {
        "id": "m0ElHvLK0ayx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### logistische Regression"
      ],
      "metadata": {
        "id": "XgoS0NMk1yia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Die logistische Regression ist eine statistische Methode zur Vorhersage binärer (zweiwertiger) Ereignisse. Sie wird häufig in der medizinischen Forschung, in der Psychologie und anderen Sozialwissenschaften eingesetzt, um die Wahrscheinlichkeit zu bestimmen, dass ein bestimmtes Ereignis eintritt, z.B. ob ein Patient an einer bestimmten Krankheit erkrankt oder nicht.\n",
        "\n",
        "Das Ziel der logistischen Regression ist es, eine Beziehung zwischen einer abhängigen Variablen (die binäre Klassifikation) und einer oder mehreren unabhängigen Variablen (den Merkmalen) zu modellieren. Die logistische Regression verwendet eine Sigmoid-Funktion, um die Wahrscheinlichkeit der Klassenzugehörigkeit zu schätzen und diese Vorhersagen als \"Ja\" oder \"Nein\" zu klassifizieren. Das Modell wird auf der Grundlage der Eingabevariablen trainiert, indem es die optimalen Parameter schätzt, um die Wahrscheinlichkeit zu maximieren, dass das Modell die beobachteten Daten korrekt vorhersagt.\n",
        "\n",
        "In der Praxis wird die logistische Regression oft als einfache und effektive Methode zur Vorhersage von Ereignissen eingesetzt, insbesondere wenn die abhängige Variable binär ist."
      ],
      "metadata": {
        "id": "fokDbEzk1tm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataFrame"
      ],
      "metadata": {
        "id": "qAH7qDMrz7Fi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ein DataFrame ist ein Datenobjekt in Pandas, das aus einer zweidimensionalen, tabellenartigen Datenstruktur besteht, die Spalten mit potenziell unterschiedlichen Datentypen enthält. Es ähnelt einer Tabelle in einer relationalen Datenbank oder einer Excel-Tabelle. DataFrame-Objekte können aus verschiedenen Quellen wie CSV-Dateien, Datenbankabfragen oder Excel-Dateien geladen werden und ermöglichen es, Daten zu manipulieren, zu transformieren und zu analysieren."
      ],
      "metadata": {
        "id": "ghvOE9Ch_Ekv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion Matrix"
      ],
      "metadata": {
        "id": "ENecHtNR2B1N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eine Konfusionsmatrix, auch Fehlermatrix genannt, ist eine Tabelle, die verwendet wird, um die Leistung eines Klassifikationsmodells zu visualisieren. Sie zeigt, wie gut das Modell in der Lage ist, Datenpunkte in verschiedenen Kategorien oder Klassen korrekt zu klassifizieren.\n",
        "\n",
        "Eine Konfusionsmatrix hat in der Regel zwei Achsen: Die erste Achse zeigt die tatsächlichen Klassen und die zweite Achse zeigt die vom Modell vorhergesagten Klassen. Die Zellen in der Matrix geben an, wie viele Datenpunkte vom Modell in eine bestimmte Kategorie klassifiziert wurden und wie viele tatsächlich in dieser Kategorie waren.\n",
        "\n",
        "Es gibt vier mögliche Ergebnisse, die in der Konfusionsmatrix angezeigt werden können:\n",
        "*   True Positive (TP): Das Modell hat die positive Klasse korrekt vorhergesagt.\n",
        "*   False Positive (FP): Das Modell hat die positive Klasse fälschlicherweise vorhergesagt.\n",
        "*   True Negative (TN): Das Modell hat die negative Klasse korrekt vorhergesagt.\n",
        "*   False Negative (FN): Das Modell hat die negative Klasse fälschlicherweise vorhergesagt.\n",
        "\n",
        "Die Konfusionsmatrix ist ein nützliches Werkzeug, um verschiedene Metriken zur Bewertung der Leistung von Klassifikationsmodellen zu berechnen, wie z.B. Genauigkeit, Präzision, Empfindlichkeit und Spezifität."
      ],
      "metadata": {
        "id": "Tj2QgVjo2Ygk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Maligne und Benigne"
      ],
      "metadata": {
        "id": "DTkEUP2j-SnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Die beiden Klassen beziehen sich auf die Diagnose \"Maligne\" (bösartig) und \"Benigne\" (gutartig) von Brustkrebs. In diesem Fall wird ein Modell trainiert, um aufgrund von bestimmten Merkmalen einer Gewebeprobe (z.B. Radius, Textur, Perimeter usw.) vorherzusagen, ob der Brustkrebs bösartig oder gutartig ist. Die Klasse \"Maligne\" steht dabei für eine bösartige Diagnose und die Klasse \"Benigne\" steht für eine gutartige Diagnose."
      ],
      "metadata": {
        "id": "FWv0U9bR-LUM"
      }
    }
  ]
}